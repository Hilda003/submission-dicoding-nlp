# -*- coding: utf-8 -*-
"""submission-dicoding-nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KZRTh9bjEI6M_slb7h8W3DqmCVuY_RJY

Nama : Hildatul Wardah
---
Link dataset: https://www.kaggle.com/datasets/marslinoedward/sms-spam-dataset
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense
import tensorflow as tf
import matplotlib.pyplot as plt

df = pd.read_csv('spam.csv')
df.head()

print(df.info())

print(df.tail())

spam_or_ham = pd.get_dummies(df['spamORham'])
df_new = pd.concat([df, spam_or_ham], axis=1)

df_new = df_new.drop(columns=['spamORham'])

messages = df_new['Message'].values
labels = df_new[['ham', 'spam']].values

messages_train, messages_test, labels_train, labels_test = train_test_split(messages, labels, test_size=0.2, random_state=42)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(messages_train)
sequences_train = tokenizer.texts_to_sequences(messages_train)
sequences_test = tokenizer.texts_to_sequences(messages_test)

padded_train = pad_sequences(sequences_train)
padded_test = pad_sequences(sequences_test, maxlen=padded_train.shape[1])

model = tf.keras.Sequential([
    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=16),
    LSTM(64),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(2, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      self.model.stop_training = True
      print("\nThe accuracy of the training set and the validation set has reached > 90%!")
callbacks = myCallback()

history = model.fit(padded_train, labels_train, epochs=10, validation_data=(padded_test, labels_test), verbose=2)

train_accuracy = model.evaluate(padded_train, labels_train, verbose=0)[1]
test_accuracy = model.evaluate(padded_test, labels_test, verbose=0)[1]

print(f"Training Accuracy: {train_accuracy:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Plot')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy Plot')
plt.legend()
plt.show()